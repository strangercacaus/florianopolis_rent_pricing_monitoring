{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7090597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T22:33:28.816416Z",
     "iopub.status.busy": "2023-10-25T22:33:28.816003Z",
     "iopub.status.idle": "2023-10-25T22:33:28.820996Z",
     "shell.execute_reply": "2023-10-25T22:33:28.819815Z"
    },
    "papermill": {
     "duration": 0.014178,
     "end_time": "2023-10-25T22:33:28.823345",
     "exception": false,
     "start_time": "2023-10-25T22:33:28.809167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! pip install html5lib\n",
    "#! pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245055d8",
   "metadata": {
    "cell_id": "e67ef1ad31fb4b8cb2868c3d9cf1f8e2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2023-10-25T22:33:28.835751Z",
     "iopub.status.busy": "2023-10-25T22:33:28.835343Z",
     "iopub.status.idle": "2023-10-25T22:33:29.565276Z",
     "shell.execute_reply": "2023-10-25T22:33:29.564025Z"
    },
    "execution_millis": 10,
    "execution_start": 1698097356201,
    "papermill": {
     "duration": 0.738187,
     "end_time": "2023-10-25T22:33:29.568059",
     "exception": false,
     "start_time": "2023-10-25T22:33:28.829872",
     "status": "completed"
    },
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Builtins\n",
    "from datetime import datetime, date\n",
    "import requests\n",
    "import string\n",
    "import time\n",
    "import re\n",
    "import base64\n",
    "\n",
    "# External Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import html5lib\n",
    "from kaggle_secrets import UserSecretsClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd2c726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T22:33:29.579064Z",
     "iopub.status.busy": "2023-10-25T22:33:29.578526Z",
     "iopub.status.idle": "2023-10-25T22:33:29.754297Z",
     "shell.execute_reply": "2023-10-25T22:33:29.752896Z"
    },
    "papermill": {
     "duration": 0.184356,
     "end_time": "2023-10-25T22:33:29.757202",
     "exception": false,
     "start_time": "2023-10-25T22:33:29.572846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "github_access_token = user_secrets.get_secret(\"github_rent_price_monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377efec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T22:33:29.768862Z",
     "iopub.status.busy": "2023-10-25T22:33:29.768091Z",
     "iopub.status.idle": "2023-10-25T22:33:29.786887Z",
     "shell.execute_reply": "2023-10-25T22:33:29.785920Z"
    },
    "papermill": {
     "duration": 0.027739,
     "end_time": "2023-10-25T22:33:29.789469",
     "exception": false,
     "start_time": "2023-10-25T22:33:29.761730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GithubApi():\n",
    "    def __init__(self, token:str, owner:str, repo:str) -> None:\n",
    "        self.token = token\n",
    "        self.owner = owner\n",
    "        self.repo = repo\n",
    "        self.base_url = f'https://api.github.com/repos/{owner}/{repo}'\n",
    "        \n",
    "    def get_url(self, file_path:str) -> str:\n",
    "        return f'{self.base_url}/contents/{file_path}'\n",
    "        \n",
    "    def get_file_info(self, file_url) -> str:\n",
    "        headers = {'Authorization': f'token {self.token}'}\n",
    "        response = requests.get(url=file_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "        download_url = response_json['download_url']\n",
    "        current_sha = response_json['sha']\n",
    "        return download_url, current_sha, file_url\n",
    "    \n",
    "    def _download_current_content(self, download_url) -> pd.DataFrame:\n",
    "        extension = download_url.split('.')[-1]\n",
    "        if extension == 'csv':\n",
    "            return pd.read_csv(download_url)\n",
    "        elif extension == 'parquet':\n",
    "            return pd.read_csv\n",
    "        else:\n",
    "            raise TypeError(f'file format {extension} is not supported')\n",
    "                \n",
    "    def _append_new_content(self,current_content=pd.DataFrame, new_content=pd.DataFrame) -> pd.DataFrame:\n",
    "        if current_content.columns == new_content.columns:\n",
    "            return pd.concat([current_content,new_content])\n",
    "    \n",
    "    def _get_encoded_content(self, appended_content=pd.DataFrame, file_format='csv'):\n",
    "        if file_format == 'csv':\n",
    "            csv_data = appended_content.to_csv()\n",
    "            return base64.b64encode(csv_data.encode()).decode('utf-8')\n",
    "        else:\n",
    "            raise TypeError(f'Unsuported file type in _get_encoded_content function')\n",
    "    \n",
    "    def _put_content(self, headers, data, url) -> requests.models.Response:\n",
    "        try:\n",
    "            response = requests.put(url=file_url, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.HTTPError as http_err:\n",
    "            print(f'HTTP error occurred: {http_err}')\n",
    "        except Exception as err:\n",
    "            print(f'Other error occurred: {err}')\n",
    "        else:\n",
    "            if response.status_code == 200:\n",
    "                print(\"File updated successfully.\")\n",
    "            else:\n",
    "                print(f\"Failed to update file. Status code: {response.status_code}\")\n",
    "    \n",
    "    def update_file_content(self, file_path, new_content, method='append') -> None:\n",
    "        file_url = self.get_url(file_path=file_path)\n",
    "        download_url, current_sha, file_url = self.get_file_info(file_url)\n",
    "        current_content = self._download_current_content(download_url)\n",
    "        if method == 'append':\n",
    "            appended_content = self._append_new_content(current_content, new_content)\n",
    "        elif method == 'overwrite':\n",
    "            appended_content = new_content\n",
    "        else:\n",
    "            raise TypeError('\"method\" must be one of \"append\" or \"overwrite\".')\n",
    "        encoded_content = self._get_encoded_content(appended_content)\n",
    "        commit_message = f\"Automatically updated via Kaggle script\"\n",
    "        headers = {'Authorization': f'token {self.token}'}\n",
    "        data = {\"message\": commit_message,\"content\": encoded_content,\"sha\": current_sha}\n",
    "        self._put_content(headers=headers, data=data, url=file_url)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34834a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T22:33:29.800728Z",
     "iopub.status.busy": "2023-10-25T22:33:29.799706Z",
     "iopub.status.idle": "2023-10-25T22:33:29.809626Z",
     "shell.execute_reply": "2023-10-25T22:33:29.808476Z"
    },
    "papermill": {
     "duration": 0.01849,
     "end_time": "2023-10-25T22:33:29.812371",
     "exception": false,
     "start_time": "2023-10-25T22:33:29.793881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_address(string):\n",
    "    formatted_chars = []\n",
    "    bairro = None\n",
    "    numero = None\n",
    "    rua = None\n",
    "    for char in string:\n",
    "        if char in \"-,/;|.\":\n",
    "            formatted_chars.append(',')\n",
    "        else:\n",
    "            formatted_chars.append(char)\n",
    "    formatted_string = ''.join(formatted_chars)\n",
    "    term_list = formatted_string.split(',')[::-1]\n",
    "    try:\n",
    "        bairro = term_list[2]\n",
    "    except:\n",
    "        bairro = None\n",
    "    try:\n",
    "        numero = int(''.join(re.findall(r'\\d', formatted_string)))\n",
    "    except:\n",
    "        numero = None\n",
    "    try:\n",
    "        rua = term_list[len(term_list)-1] if len(term_list) > 1 else None\n",
    "    except:\n",
    "        rua = None\n",
    "    return dict(\n",
    "        bairro = bairro,\n",
    "        numero = numero,\n",
    "        rua = rua\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34cc7e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T22:33:29.823529Z",
     "iopub.status.busy": "2023-10-25T22:33:29.823118Z",
     "iopub.status.idle": "2023-10-25T22:33:29.862609Z",
     "shell.execute_reply": "2023-10-25T22:33:29.861302Z"
    },
    "papermill": {
     "duration": 0.047844,
     "end_time": "2023-10-25T22:33:29.864890",
     "exception": false,
     "start_time": "2023-10-25T22:33:29.817046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VivaRealApi():\n",
    "    def __init__(self, cidade:str) -> None:\n",
    "        self.type = 'Viva Real'\n",
    "        self.current_page = 1\n",
    "        self.city = cidade\n",
    "        self.endpoint = f'https://www.vivareal.com.br/aluguel/santa-catarina/{self.city}/?pagina='\n",
    "        self.result_set = pd.DataFrame(\n",
    "            {'data': pd.Series(dtype='datetime64[ns]'),\n",
    "             'fonte': pd.Series(dtype='str'),\n",
    "             'descricao': pd.Series(dtype='str'),\n",
    "             'endereco': pd.Series(dtype='str'),\n",
    "             'rua': pd.Series(dtype='str'),\n",
    "             'numero': pd.Series(dtype='int'),\n",
    "             'bairro': pd.Series(dtype='str'),\n",
    "             'cidade': pd.Series(dtype='str'),\n",
    "             'valor': pd.Series(dtype='float'),\n",
    "             'periodicidade': pd.Series(dtype='str'),\n",
    "             'condominio': pd.Series(dtype='float'),\n",
    "             'area': pd.Series(dtype='float'),\n",
    "             'qtd_banheiros': pd.Series(dtype='int'),\n",
    "             'qtd_quartos': pd.Series(dtype='int'),\n",
    "             'qtd_vagas': pd.Series(dtype='int'),\n",
    "             'url': pd.Series(dtype='str')\n",
    "                  }\n",
    "        )\n",
    "\n",
    "    def _get_endpoint(self) -> str:\n",
    "        return f'{self.endpoint}{self.city}'\n",
    "    \n",
    "    def _extract_current_page(self, max_retries=5, backoff_factor=2) -> requests.models.Response:\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            response = requests.get(self._get_endpoint())\n",
    "            if response.status_code < 300:  # Successful response\n",
    "                return response\n",
    "            elif response.status_code == 429:  # Too many requests\n",
    "                print(f\"Rate limited. Retrying in {backoff_factor ** retries} seconds.\")\n",
    "                time.sleep(backoff_factor ** retries)\n",
    "                retries += 1\n",
    "            else:\n",
    "                print(f\"Request failed with status code {response.status_code}\")\n",
    "                return None\n",
    "    \n",
    "    def _parse_html_response(self, response=None) -> bs4.BeautifulSoup:\n",
    "        if response and response.status_code < 300:\n",
    "            return bs4.BeautifulSoup(response.text, features=\"html5lib\")\n",
    "        elif response:\n",
    "            print(f'No valid response to be parsed. Status code {response.status_code}.')\n",
    "            return None\n",
    "        else:\n",
    "            print('Empty request')\n",
    "        \n",
    "    @property\n",
    "    def _result_count(self) -> int:\n",
    "        response = self._extract_current_page()\n",
    "        soup = self._parse_html_response(response=response)\n",
    "        try:\n",
    "            return int(soup.find('strong',{'class':'results-summary__count'}).text.replace('.',''))\n",
    "        except:\n",
    "            print(f'No houses were found for the given page.\\n the HTML structure of the page might have been altered...')\n",
    "            return 0\n",
    "        \n",
    "    def _extract_listings_from_soup(self, soup) -> bs4.element.ResultSet:\n",
    "        return soup.find_all('article', {'class': 'property-card__container js-property-card'})\n",
    "    \n",
    "    def _format_listing(self, listing=None) -> list:\n",
    "            data = datetime.now()\n",
    "            fonte = self.type\n",
    "            cidade = self.city\n",
    "            formatted = []\n",
    "            try:\n",
    "                descricao = listing.find('span', {'class': 'js-card-title'}).text.strip()\n",
    "            except:\n",
    "                descricao = None\n",
    "            try:\n",
    "                endereco = listing.find('span', {'class': 'property-card__address'}).text.replace('-',',').replace('|','').strip()\n",
    "            except:\n",
    "                endereco = ''\n",
    "            try:\n",
    "                rua = extract_address(endereco)['rua']\n",
    "            except:\n",
    "                rua = None\n",
    "            try:\n",
    "                numero = extract_address(endereco)['numero']\n",
    "                numero = int(''.join(re.findall(r'\\d', numero)))\n",
    "            except:\n",
    "                numero = None   \n",
    "            try:\n",
    "                bairro = extract_address(endereco)['bairro']\n",
    "            except:\n",
    "                bairro = None\n",
    "            try:\n",
    "                valor = listing.find('div', {'class': 'property-card__price'}).text.replace('R$','').replace('.','').split('/')[0]\n",
    "            except:\n",
    "                valor = None\n",
    "            try:\n",
    "                periodicidade = listing.find('div', {'class': 'property-card__price'}).text.replace('R$','').replace('.','').split('/')[1].split(' ')[0]\n",
    "            except:\n",
    "                periodicidade = None\n",
    "            try:\n",
    "                condominio = listing.find('strong', {'class': 'js-condo-price'}).text.replace('R$','').strip()\n",
    "            except:\n",
    "                condominio = None\n",
    "            try:\n",
    "                area = listing.find('span', {'class': 'js-property-card-detail-area'}).text.strip()\n",
    "            except:\n",
    "                area = None\n",
    "            try:\n",
    "                qtd_banheiros = listing.find('li', {'class': 'property-card__detail-bathroom'}).text.strip()[0]\n",
    "                qtd_banheiros = int(''.join(re.findall(r'\\d', qtd_banheiros)))\n",
    "            except:\n",
    "                qtd_banheiros = None\n",
    "            try:\n",
    "                qtd_quartos = listing.find('li', {'class': 'property-card__detail-room'}).text.strip()[0]\n",
    "                qtd_quartos = int(''.join(re.findall(r'\\d', qtd_quartos)))\n",
    "            except:\n",
    "                qtd_quartos = None\n",
    "            try:\n",
    "                qtd_vagas = listing.find('li', {'class': 'property-card__detail-garage'}).text.strip()[0]\n",
    "                qtd_vagas = int(''.join(re.findall(r'\\d', qtd_vagas)))\n",
    "            except:\n",
    "                qtd_vagas = None\n",
    "            try:\n",
    "                link = 'https://vivareal.com.br' + listing.find('a', {'class': 'property-card__labels-container'})['href']\n",
    "            except:\n",
    "                link = None\n",
    "            return [data,fonte,descricao,endereco,rua,numero,bairro,cidade,valor,periodicidade,condominio,area,qtd_banheiros,qtd_quartos,qtd_vagas,link]\n",
    "    \n",
    "    def _append_formatted_listing(self, listing=None) -> None:\n",
    "        try:\n",
    "            self.result_set.loc[self.result_set.shape[0]] = listing\n",
    "        except:\n",
    "            print(f'Error appending the following listing:\\n{listing}')\n",
    "    \n",
    "    def _ingest_current_page(self) -> None:\n",
    "        try:\n",
    "            print(f'Current_page: {self.current_page}')\n",
    "            response = self._extract_current_page()\n",
    "            soup = self._parse_html_response(response=response)\n",
    "            listings = self._extract_listings_from_soup(soup=soup)\n",
    "            for i in listings:\n",
    "                formatted = self._format_listing(listing = i)\n",
    "                self._append_formatted_listing(listing=formatted)\n",
    "        except exception:\n",
    "            print(f'Something went wrong while formating the listings of the page {self.current_page}: {exception}')\n",
    "        else:\n",
    "            self.current_page += 1\n",
    "    \n",
    "    def ingest_listings(self, all=True, pages_number=None) -> None:\n",
    "        if all == True:\n",
    "            while self.result_set.shape[0] < self._result_count:\n",
    "                self._ingest_current_page()\n",
    "        elif pages_number:\n",
    "            if type(pages_number) == int and pages_number > 0:\n",
    "                self.current_page = 1\n",
    "                while self.current_page <= pages_number:\n",
    "                    self._ingest_current_page()\n",
    "            else:\n",
    "                raise TypeError('pages_number: This parameter only accepts numbers above zero.')\n",
    "                \n",
    "    def dump_result_set(self, path=None, format='csv') -> None:\n",
    "        if format=='csv':\n",
    "            self.result_set.to_csv(f'{path}{self.city}_{date.today()}.csv')\n",
    "        elif format=='parquet':\n",
    "            self.result_set.to_parquet(f'{path}{self.city}_{date.today()}.parquet')\n",
    "        else:\n",
    "            print(f'Option not allowed: {format}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b345c5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T22:33:29.876018Z",
     "iopub.status.busy": "2023-10-25T22:33:29.875123Z",
     "iopub.status.idle": "2023-10-25T22:43:46.898621Z",
     "shell.execute_reply": "2023-10-25T22:43:46.897424Z"
    },
    "papermill": {
     "duration": 617.032773,
     "end_time": "2023-10-25T22:43:46.902079",
     "exception": false,
     "start_time": "2023-10-25T22:33:29.869306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current_page: 1\n",
      "Current_page: 2\n",
      "Current_page: 3\n",
      "Current_page: 4\n",
      "Current_page: 5\n",
      "Current_page: 6\n",
      "Current_page: 7\n",
      "Current_page: 8\n",
      "Current_page: 9\n",
      "Current_page: 10\n",
      "Current_page: 11\n",
      "Current_page: 12\n",
      "Current_page: 13\n",
      "Current_page: 14\n",
      "Current_page: 15\n",
      "Current_page: 16\n",
      "Current_page: 17\n",
      "Current_page: 18\n",
      "Current_page: 19\n",
      "Current_page: 20\n",
      "Current_page: 21\n",
      "Current_page: 22\n",
      "Current_page: 23\n",
      "Current_page: 24\n",
      "Current_page: 25\n",
      "Current_page: 26\n",
      "Current_page: 27\n",
      "Current_page: 28\n",
      "Current_page: 29\n",
      "Current_page: 30\n",
      "Current_page: 31\n",
      "Current_page: 32\n",
      "Current_page: 33\n",
      "Current_page: 34\n",
      "Current_page: 35\n",
      "Current_page: 36\n",
      "Current_page: 37\n",
      "Current_page: 38\n",
      "Current_page: 39\n",
      "Current_page: 40\n",
      "Current_page: 41\n",
      "Current_page: 42\n",
      "Current_page: 43\n",
      "Current_page: 44\n",
      "Current_page: 45\n",
      "Current_page: 46\n",
      "Current_page: 47\n",
      "Current_page: 48\n",
      "Current_page: 49\n",
      "Current_page: 50\n",
      "Current_page: 51\n",
      "Current_page: 52\n",
      "Current_page: 53\n",
      "Current_page: 54\n",
      "Current_page: 55\n",
      "Current_page: 56\n",
      "Current_page: 57\n",
      "Current_page: 58\n",
      "Current_page: 59\n",
      "Current_page: 60\n",
      "Current_page: 61\n",
      "Current_page: 62\n",
      "Current_page: 63\n",
      "Current_page: 64\n",
      "Current_page: 65\n",
      "Current_page: 66\n",
      "Current_page: 67\n",
      "Current_page: 68\n",
      "Current_page: 69\n",
      "Current_page: 70\n",
      "Current_page: 71\n",
      "Current_page: 72\n",
      "Current_page: 73\n",
      "Current_page: 74\n",
      "Current_page: 75\n",
      "Current_page: 76\n",
      "Current_page: 77\n",
      "Current_page: 78\n",
      "Current_page: 79\n",
      "Current_page: 80\n",
      "Current_page: 81\n",
      "Current_page: 82\n",
      "Current_page: 83\n",
      "Current_page: 84\n",
      "Current_page: 85\n",
      "Current_page: 86\n",
      "Current_page: 87\n",
      "Current_page: 88\n",
      "Current_page: 89\n",
      "Current_page: 90\n",
      "Current_page: 91\n",
      "Current_page: 92\n",
      "Current_page: 93\n",
      "Current_page: 94\n",
      "Current_page: 95\n",
      "Current_page: 96\n",
      "Current_page: 97\n",
      "Current_page: 98\n",
      "Current_page: 99\n",
      "Current_page: 100\n",
      "Current_page: 101\n",
      "Current_page: 102\n",
      "Current_page: 103\n",
      "Current_page: 104\n",
      "Current_page: 105\n",
      "Current_page: 106\n",
      "Current_page: 107\n",
      "Current_page: 108\n",
      "Current_page: 109\n",
      "Current_page: 110\n",
      "Current_page: 111\n",
      "Current_page: 112\n",
      "Current_page: 113\n",
      "Current_page: 114\n",
      "Current_page: 115\n",
      "Current_page: 116\n",
      "Current_page: 117\n",
      "Current_page: 118\n",
      "Current_page: 119\n",
      "Current_page: 120\n",
      "Current_page: 121\n",
      "Current_page: 122\n",
      "Current_page: 123\n",
      "Current_page: 124\n",
      "Current_page: 125\n",
      "Current_page: 126\n",
      "Current_page: 127\n",
      "Current_page: 128\n",
      "Current_page: 129\n",
      "Current_page: 130\n",
      "Current_page: 131\n",
      "Current_page: 132\n",
      "Current_page: 133\n",
      "Current_page: 134\n",
      "Current_page: 135\n",
      "Current_page: 136\n",
      "Current_page: 137\n",
      "Current_page: 138\n",
      "Current_page: 139\n",
      "Current_page: 140\n",
      "Current_page: 141\n",
      "Current_page: 142\n",
      "Current_page: 143\n",
      "Current_page: 144\n",
      "Current_page: 145\n",
      "Current_page: 146\n",
      "Current_page: 147\n",
      "Current_page: 148\n",
      "Current_page: 149\n",
      "Current_page: 150\n",
      "Current_page: 151\n",
      "Current_page: 152\n",
      "Current_page: 153\n",
      "Current_page: 154\n",
      "Current_page: 155\n",
      "Current_page: 156\n",
      "Current_page: 157\n",
      "Current_page: 158\n",
      "Current_page: 159\n",
      "Current_page: 160\n",
      "Current_page: 161\n",
      "Current_page: 162\n",
      "Current_page: 163\n",
      "Current_page: 164\n",
      "Current_page: 165\n",
      "Current_page: 166\n",
      "Current_page: 167\n",
      "Current_page: 168\n",
      "Current_page: 169\n",
      "Current_page: 170\n",
      "Current_page: 171\n",
      "Current_page: 172\n",
      "Current_page: 173\n",
      "Current_page: 174\n",
      "Current_page: 175\n",
      "Current_page: 176\n",
      "Current_page: 177\n",
      "Current_page: 178\n",
      "Current_page: 179\n",
      "Current_page: 180\n",
      "Current_page: 181\n",
      "Current_page: 182\n",
      "Current_page: 183\n",
      "Current_page: 184\n",
      "Current_page: 185\n",
      "Current_page: 186\n",
      "Current_page: 187\n",
      "Current_page: 188\n",
      "Current_page: 189\n",
      "Current_page: 190\n",
      "Current_page: 191\n",
      "Current_page: 192\n",
      "Current_page: 193\n",
      "Current_page: 194\n",
      "Current_page: 195\n",
      "Current_page: 196\n",
      "Current_page: 197\n",
      "Current_page: 198\n",
      "Current_page: 199\n",
      "Current_page: 200\n",
      "Current_page: 201\n",
      "Current_page: 202\n",
      "Current_page: 203\n",
      "Current_page: 204\n",
      "Current_page: 205\n",
      "Current_page: 206\n"
     ]
    }
   ],
   "source": [
    "api = VivaRealApi('florianopolis')\n",
    "api.ingest_listings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c634a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T22:43:46.955834Z",
     "iopub.status.busy": "2023-10-25T22:43:46.955146Z",
     "iopub.status.idle": "2023-10-25T22:43:46.960657Z",
     "shell.execute_reply": "2023-10-25T22:43:46.959628Z"
    },
    "papermill": {
     "duration": 0.03319,
     "end_time": "2023-10-25T22:43:46.963236",
     "exception": false,
     "start_time": "2023-10-25T22:43:46.930046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "git = GithubApi(\n",
    "    token=github_access_token,\n",
    "    owner='strangercacaus',\n",
    "    repo='florianopolis_rent_pricing_monitoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d4d10c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T22:43:47.011051Z",
     "iopub.status.busy": "2023-10-25T22:43:47.010406Z",
     "iopub.status.idle": "2023-10-25T22:43:47.651905Z",
     "shell.execute_reply": "2023-10-25T22:43:47.650481Z"
    },
    "papermill": {
     "duration": 0.668546,
     "end_time": "2023-10-25T22:43:47.654419",
     "exception": false,
     "start_time": "2023-10-25T22:43:46.985873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other error occurred: name 'file_url' is not defined\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset.csv'\n",
    "new_content = api.result_set\n",
    "method = 'overwrite'\n",
    "git.update_file_content(file_path, new_content, method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 623.223549,
   "end_time": "2023-10-25T22:43:48.301878",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-25T22:33:25.078329",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
