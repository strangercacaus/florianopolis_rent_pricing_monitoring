{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#! pip install html5lib\n#! pip install bs4","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:43.610177Z","iopub.execute_input":"2023-10-27T19:47:43.610691Z","iopub.status.idle":"2023-10-27T19:47:43.617293Z","shell.execute_reply.started":"2023-10-27T19:47:43.610637Z","shell.execute_reply":"2023-10-27T19:47:43.615922Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Builtins\nfrom datetime import datetime, date\nimport requests\nimport string\nimport time\nimport re\nimport base64\nfrom random import randint\n\n# Bibliotecas Externas\nimport numpy as np\nimport pandas as pd\nimport bs4\nimport html5lib\nfrom kaggle_secrets import UserSecretsClient\n","metadata":{"source_hash":null,"execution_start":1698097356201,"execution_millis":10,"deepnote_to_be_reexecuted":false,"cell_id":"e67ef1ad31fb4b8cb2868c3d9cf1f8e2","deepnote_cell_type":"code","execution":{"iopub.status.busy":"2023-10-27T19:47:43.620027Z","iopub.execute_input":"2023-10-27T19:47:43.620428Z","iopub.status.idle":"2023-10-27T19:47:43.642033Z","shell.execute_reply.started":"2023-10-27T19:47:43.620393Z","shell.execute_reply":"2023-10-27T19:47:43.640608Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Importação de Chaves para integração com o Github\nuser_secrets = UserSecretsClient()\ngithub_access_token = user_secrets.get_secret(\"github_rent_price_monitoring\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:43.643944Z","iopub.execute_input":"2023-10-27T19:47:43.644350Z","iopub.status.idle":"2023-10-27T19:47:43.995899Z","shell.execute_reply.started":"2023-10-27T19:47:43.644317Z","shell.execute_reply":"2023-10-27T19:47:43.994617Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Classe GithubAPI: Gerencia a integração do notebook com o Github\n\nclass GithubApi():\n    def __init__(self, token:str, owner:str, repo:str) -> None:\n        \"\"\"\n        Inicia a classe GithubApi com o token de autenticação, usuário e repositório.\n        \n        Args:\n        - token: string do token pessoal ou fine-grained.\n        - owner: nome de usuário\n        - repo: nome do repositório a ser conectado\n        \n        Retorna:\n        Uma instância do objeto GithubApi\n        \"\"\"\n        self.token = token\n        self.owner = owner\n        self.repo = repo\n        self.base_url = f'https://api.github.com/repos/{owner}/{repo}'\n        \n    def get_url(self, file_path:str) -> str:\n        \"\"\"\n        Retorna uma url formatada com os parâmetros da api do usuário\n        \n        Args:\n        - file_path: O caminho para o arquivo dentro do repositório\n        \n        Retorna:\n        URL no formato\n        ```python\n        api.get_url('file.csv')\n        # https://api.github/.com/repos/cacau/florianopolis_rent_pricing_monitoring/file.csv\n        ```\n        \"\"\"\n        return f'{self.base_url}/contents/{file_path}'\n        \n    def get_file_info(self, file_url) -> str:\n        \"\"\"\n        Recupera as informações de armazenamento de um arquivo de um repositório do Github\n        \n        Args:\n        = file_url: url do arquivo obtida com a função get_url.\n        \n        Retorna:\n        download_url: Url direta do conteúdo do arquivo.\n        current_sha: chave criptografada com permissão de alterar o arquivo\n        file_url: URL de local do arquivo fornecida pelo github\n        \"\"\"\n        headers = {'Authorization': f'token {self.token}'}\n        response = requests.get(url=file_url, headers=headers)\n        response.raise_for_status()\n        response_json = response.json()\n        download_url = response_json['download_url']\n        current_sha = response_json['sha']\n        return download_url, current_sha\n    \n    def _download_current_content(self, download_url) -> pd.DataFrame:\n        \"\"\"\n        Baixa o conteúdo do arquivo a partir da url de download.\n        \n        O Método self._download_current_content analisa a string da url de download para identificar\n        o formato de arquivo e então utiliza um método de extração adequado para o tipo de formato.\n        \n        No momenro apenas o download de arquivos csv está implementado com a função pd.read_csv.\n        \n        Args:\n        - download_url: url do arquivo obtida com a função get_file_info.\n        \n        Retorna:\n        Dataframe Pandas com os valores do arquivo.\n        \"\"\"\n        extension = download_url.split('.')[-1]\n        if extension == 'csv':\n            return pd.read_csv(download_url,index_col=0)\n        elif extension == 'parquet':\n            return pd.read_csv\n        else:\n            raise TypeError(f'file format {extension} is not supported')\n                \n    def _append_new_content(self,current_content=pd.DataFrame, new_content=pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Adiciona o conteúdo do novo result_set ao Dataframe existente.\n        \n        Kwargs:\n        - current_content: Dataframe do dataset atual. \n        - new_content: Dataframe do novo result_set.\n        \n        Retorna:\n        Dataframe Pandas com os valores unidos.\n        \"\"\"\n        return pd.concat([current_content,new_content])\n    \n    def _get_encoded_content(self, appended_content=pd.DataFrame, file_format='csv'):\n        \"\"\"\n        Formata o conteúdo do dataframe para inclusão no Github\n        \n        Kwargs:\n        - appended_content: Dataframe com os valores a serem codificados para envio.\n        - file_format: O formato para codificação, CSV por padrão.\n        \n        Retorna:\n        Arquivo base64 na codificação desejada.\n        \"\"\"\n        if file_format == 'csv':\n            csv_data = appended_content.to_csv()\n            return base64.b64encode(csv_data.encode()).decode('utf-8')\n        else:\n            raise TypeError(f'Unsuported file type in _get_encoded_content function')\n    \n    def _put_content(self, headers, data, url) -> requests.models.Response:\n        \"\"\"\n        Realiza requisição PUT com payload formatado.\n        \n        Kwargs:\n        - appended_content: Dataframe com os valores a serem configurados para envio.\n        \n        Retorna:\n        Arquivo base64 na codificação desejada.\n        \"\"\"\n        try:\n            response = requests.put(url=file_url, headers=headers, json=data)\n            response.raise_for_status()\n            return response\n        except requests.HTTPError as http_err:\n            print(f'HTTP error occurred: {http_err}')\n        except Exception as err:\n            print(f'Other error occurred: {err}')\n        else:\n            if response.status_code == 200:\n                print(\"File updated successfully.\")\n            else:\n                print(f\"Failed to update file. Status code: {response.status_code}\")\n    \n    def update_file_content(self, file_path, new_content, method='append') -> None:\n        \"\"\"\n        Realiza o update do conteúdo de um arquivo a partir de um path e um novo conteúdo.\n        \n        Args:\n        - file_path: o caminho do arquivo dentro do repositório.\n        - new_content: o Dataframe com o conteúdo a ser inserido.\n        \n        Kwargs:\n        - method: 'append' Adiciona o novo conteúdo ao existente | 'overwrite' sobrescreve o conteúdo com o novo.\n        \"\"\"\n        file_url = self.get_url(file_path=file_path)\n        download_url, current_sha = self.get_file_info(file_url)\n        current_content = self._download_current_content(download_url)\n        if method == 'append':\n            appended_content = self._append_new_content(current_content, new_content)\n        elif method == 'overwrite':\n            appended_content = new_content\n        else:\n            raise TypeError('\"method\" must be one of \"append\" or \"overwrite\".')\n        encoded_content = self._get_encoded_content(appended_content)\n        commit_message = f\"Automatically updated via Kaggle script\"\n        headers = {'Authorization': f'token {self.token}'}\n        data = {\"message\": commit_message,\"content\": encoded_content,\"sha\": current_sha}\n        self._put_content(headers=headers, data=data, url=file_url)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:43.999024Z","iopub.execute_input":"2023-10-27T19:47:43.999632Z","iopub.status.idle":"2023-10-27T19:47:44.039732Z","shell.execute_reply.started":"2023-10-27T19:47:43.999586Z","shell.execute_reply":"2023-10-27T19:47:44.037901Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def extract_address(string):\n    formatted_chars = []\n    bairro = None\n    numero = None\n    rua = None\n    for char in string:\n        if char in \"-,/;|.\":\n            formatted_chars.append(',')\n        else:\n            formatted_chars.append(char)\n    formatted_string = ''.join(formatted_chars)\n    term_list = formatted_string.split(',')[::-1]\n    try:\n        bairro = term_list[2]\n    except:\n        bairro = None\n    try:\n        numero = int(''.join(re.findall(r'\\d', formatted_string)))\n    except:\n        numero = None\n    try:\n        rua = term_list[len(term_list)-1] if len(term_list) > 1 else None\n    except:\n        rua = None\n    return dict(\n        bairro = bairro,\n        numero = numero,\n        rua = rua\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:44.042154Z","iopub.execute_input":"2023-10-27T19:47:44.042725Z","iopub.status.idle":"2023-10-27T19:47:44.060528Z","shell.execute_reply.started":"2023-10-27T19:47:44.042638Z","shell.execute_reply":"2023-10-27T19:47:44.058710Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class VivaRealApi():\n    def __init__(self, cidade:str, delay_seconds=0) -> None:\n        self.type = 'Viva Real'\n        self.current_page = 1\n        self.city = cidade\n        self.delay_seconds = delay_seconds\n        self._last_http_response = None\n        self.result_set = pd.DataFrame(\n            {'data': pd.Series(dtype='datetime64[ns]'),\n             'fonte': pd.Series(dtype='str'),\n             'descricao': pd.Series(dtype='str'),\n             'endereco': pd.Series(dtype='str'),\n             'rua': pd.Series(dtype='str'),\n             'numero': pd.Series(dtype='int'),\n             'bairro': pd.Series(dtype='str'),\n             'cidade': pd.Series(dtype='str'),\n             'valor': pd.Series(dtype='float'),\n             'periodicidade': pd.Series(dtype='str'),\n             'condominio': pd.Series(dtype='float'),\n             'area': pd.Series(dtype='float'),\n             'qtd_banheiros': pd.Series(dtype='int'),\n             'qtd_quartos': pd.Series(dtype='int'),\n             'qtd_vagas': pd.Series(dtype='int'),\n             'url': pd.Series(dtype='str')\n                  })\n        \n    @property\n    def endpoint(self) -> str:\n        return f'https://www.vivareal.com.br/aluguel/santa-catarina/{self.city}/?pagina='\n    \n    @property\n    def _first_page(self) -> bs4.BeautifulSoup:\n        response = self._extract_current_page()\n        return self._parse_html_response(response=response)\n    \n    @property\n    def _result_count(self) -> int:\n        soup = self._first_page\n        try:\n            return int(soup.find('strong',{'class':'results-summary__count'}).text.replace('.',''))\n        except:\n            print(f'No houses were found for the given page.\\n the HTML structure of the page might have been altered...')\n            return 0\n        \n    @property\n    def _results_per_page(self) -> int:\n        soup = self._first_page\n        listings = self._extract_listings_from_soup(soup=soup)\n        return len(listings)\n    \n    def _get_endpoint(self) -> str:\n        seed = randint(1,6)\n        \n        match seed:\n            case 1:\n                return f'{self.endpoint}{self.current_page}#onde=Brasil,Santa%20Catarina,Florian%C3%B3polis,,,,,,BR%3ESanta%20Catarina%3ENULL%3EFlorianopolis,,,'\n            case 2:\n                return f'{self.endpoint}{self.current_page}'\n            case 3:\n                return f'{self.endpoint}{self.current_page}#onde=Florian%C3%B3polis,,,'\n            case 4:\n                return f'{self.endpoint}{self.current_page}#onde=Brasil,Santa%20Catarina,Florian%C3%B3polis,,BR%3ESanta%20Catarina%3ENULL%3EFlorianopolis,,,'\n            case 5:\n                return f'{self.endpoint}{self.current_page}#onde=Brasil,Santa%20Catarina,Florian%C3%B3polis,,,,BR%3ESanta%20Catarina%3ENULL%3EFlorianopolis,,,'\n            case 6:\n                return f'{self.endpoint}{self.current_page}#onde=,Santa%20Catarina,Florian%C3%B3polis,,,,,,,city,BR%3ESanta%20Catarina%3ENULL%3EFlorianopolis,,,'\n    \n    def _get_new_page_number(self) -> int:\n        return randint(1,round(self._result_count/self._results_per_page))\n    \n    def _extract_current_page(self, max_retries=5, backoff_factor=2) -> requests.models.Response:\n        retries = 0\n        while retries < max_retries:\n            if self.current_page > 1:\n                time.sleep(self.delay_seconds) \n            response = requests.get(self._get_endpoint())\n            if response.status_code < 300:  # Successful response\n                return response\n            elif response.status_code == 429:  # Too many requests\n                print(f\"Rate limited. Retrying in {backoff_factor ** retries} seconds.\")\n                time.sleep(backoff_factor ** retries)\n                retries += 1\n            else:\n                print(f\"Request failed with status code {response.status_code}\")\n                return None\n            self._last_http_response = response.status_code\n    \n    def _parse_html_response(self, response=None) -> bs4.BeautifulSoup:\n        if response and response.status_code < 300:\n            return bs4.BeautifulSoup(response.text, features=\"html5lib\")\n        elif response:\n            print(f'No valid response to be parsed. Status code {response.status_code}.')\n            return None\n        else:\n            print('Empty request')\n        \n    def _extract_listings_from_soup(self, soup) -> bs4.element.ResultSet:\n        return soup.find_all('article', {'class': 'property-card__container js-property-card'})\n    \n    def _format_listing(self, listing=None) -> list:\n            data = datetime.now()\n            fonte = self.type\n            cidade = self.city\n            formatted = []\n            try:\n                descricao = listing.find('span', {'class': 'js-card-title'}).text.strip()\n            except:\n                descricao = None\n            try:\n                endereco = listing.find('span', {'class': 'property-card__address'}).text.replace('-',',').replace('|','').strip()\n            except:\n                endereco = ''\n            try:\n                rua = extract_address(endereco)['rua']\n            except:\n                rua = None\n            try:\n                numero = extract_address(endereco)['numero']\n            except:\n                numero = None   \n            try:\n                bairro = extract_address(endereco)['bairro']\n            except:\n                bairro = None\n            try:\n                valor = listing.find('div', {'class': 'property-card__price'}).text.replace('R$','').replace('.','').split('/')[0]\n            except:\n                valor = None\n            try:\n                periodicidade = listing.find('div', {'class': 'property-card__price'}).text.replace('R$','').replace('.','').split('/')[1].split(' ')[0]\n            except:\n                periodicidade = None\n            try:\n                condominio = listing.find('strong', {'class': 'js-condo-price'}).text.replace('R$','').strip()\n            except:\n                condominio = None\n            try:\n                area = listing.find('span', {'class': 'js-property-card-detail-area'}).text.strip()\n            except:\n                area = None\n            try:\n                qtd_banheiros = listing.find('li', {'class': 'property-card__detail-bathroom'}).text.strip()[0]\n                qtd_banheiros = int(''.join(re.findall(r'\\d', qtd_banheiros)))\n            except:\n                qtd_banheiros = None\n            try:\n                qtd_quartos = listing.find('li', {'class': 'property-card__detail-room'}).text.strip()[0]\n                qtd_quartos = int(''.join(re.findall(r'\\d', qtd_quartos)))\n            except:\n                qtd_quartos = None\n            try:\n                qtd_vagas = listing.find('li', {'class': 'property-card__detail-garage'}).text.strip()[0]\n                qtd_vagas = int(''.join(re.findall(r'\\d', qtd_vagas)))\n            except:\n                qtd_vagas = None\n            try:\n                link = 'https://vivareal.com.br' + listing.find('a', {'class': 'property-card__labels-container'})['href']\n            except:\n                link = None\n            return [data,fonte,descricao,endereco,rua,numero,bairro,cidade,valor,periodicidade,condominio,area,qtd_banheiros,qtd_quartos,qtd_vagas,link]\n    \n    def _append_formatted_listing(self, listing=None) -> None:\n        try:\n            if not listing[-1] in self.result_set['url'].to_list():\n                self.result_set.loc[self.result_set.shape[0]] = listing\n                return True\n        except:\n            print(f'Error appending the following listing:\\n{listing}')\n            return False\n        else:\n            return False\n    \n    def _ingest_current_page(self) -> None:\n        try:\n            print(f'Current_page: {self.current_page}')\n            response = self._extract_current_page()\n            soup = self._parse_html_response(response=response)\n            listings = self._extract_listings_from_soup(soup=soup)\n            added_listings = 0\n            for i in listings:\n                formatted = self._format_listing(listing = i)\n                success = self._append_formatted_listing(listing=formatted)\n                if success == True:\n                    added_listings += 1\n        except exception:\n            print(f'Something went wrong while formating the listings of the page {self.current_page}: {exception}')\n        else:\n            print(f'{added_listings} novos anúncios adicionados na página {self.current_page}')\n            self.current_page = self._get_new_page_number()\n    \n    def ingest_listings(self, all=True, max_attempts=None) -> None:\n        attempts = 0\n        if all == True:\n            while self.result_set.shape[0] < self._result_count:\n                    self._ingest_current_page()\n                    attempts += 1\n        elif max_attempts:\n            if type(max_attempts) == int and max_attempts > 0:\n                self.current_page = 1\n                while attempts <= max_attempts:\n                    self._ingest_current_page()\n                    attempts += 1\n            else:\n                raise TypeError('pages_number: This parameter only accepts numbers above zero.')\n                \n    def dump_result_set(self, path=None, format='csv') -> None:\n        if format=='csv':\n            self.result_set.to_csv(f'{path}{self.city}_{date.today()}.csv')\n        elif format=='parquet':\n            self.result_set.to_parquet(f'{path}{self.city}_{date.today()}.parquet')\n        else:\n            print(f'Option not allowed: {format}')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:44.062860Z","iopub.execute_input":"2023-10-27T19:47:44.064460Z","iopub.status.idle":"2023-10-27T19:47:44.118757Z","shell.execute_reply.started":"2023-10-27T19:47:44.064402Z","shell.execute_reply":"2023-10-27T19:47:44.117199Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"api = VivaRealApi('florianopolis',delay_seconds=2)\napi.ingest_listings(all=False, max_attempts=2)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:44.120633Z","iopub.execute_input":"2023-10-27T19:47:44.121507Z","iopub.status.idle":"2023-10-27T19:47:59.186713Z","shell.execute_reply.started":"2023-10-27T19:47:44.121311Z","shell.execute_reply":"2023-10-27T19:47:59.184485Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Current_page: 1\n36 novos anúncios adicionados na página 1\nCurrent_page: 182\n0 novos anúncios adicionados na página 182\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m api \u001b[38;5;241m=\u001b[39m VivaRealApi(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflorianopolis\u001b[39m\u001b[38;5;124m'\u001b[39m,delay_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mingest_listings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[6], line 201\u001b[0m, in \u001b[0;36mVivaRealApi.ingest_listings\u001b[0;34m(self, all, max_attempts)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m attempts \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_attempts:\n\u001b[0;32m--> 201\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ingest_current_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m         attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","Cell \u001b[0;32mIn[6], line 189\u001b[0m, in \u001b[0;36mVivaRealApi._ingest_current_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00madded_listings\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m novos anúncios adicionados na página \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_new_page_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[6], line 69\u001b[0m, in \u001b[0;36mVivaRealApi._get_new_page_number\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_page_number\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m randint(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_count\u001b[38;5;241m/\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_results_per_page\u001b[49m))\n","Cell \u001b[0;32mIn[6], line 47\u001b[0m, in \u001b[0;36mVivaRealApi._results_per_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_results_per_page\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first_page\u001b[49m\n\u001b[1;32m     48\u001b[0m     listings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_listings_from_soup(soup\u001b[38;5;241m=\u001b[39msoup)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(listings)\n","Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mVivaRealApi._first_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_first_page\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m bs4\u001b[38;5;241m.\u001b[39mBeautifulSoup:\n\u001b[0;32m---> 33\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_current_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_html_response(response\u001b[38;5;241m=\u001b[39mresponse)\n","Cell \u001b[0;32mIn[6], line 75\u001b[0m, in \u001b[0;36mVivaRealApi._extract_current_page\u001b[0;34m(self, max_retries, backoff_factor)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retries \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelay_seconds\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     76\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_endpoint())\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:  \u001b[38;5;66;03m# Successful response\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"df = api.result_set\ndf['area'] = df['area'].astype('float')\ndf['valor'] = df[['valor']].astype('float')\ndf.plot(kind='scatter',x='area',y='valor')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:59.187601Z","iopub.status.idle":"2023-10-27T19:47:59.188029Z","shell.execute_reply.started":"2023-10-27T19:47:59.187829Z","shell.execute_reply":"2023-10-27T19:47:59.187849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"git = GithubApi(\n    token=github_access_token,\n    owner='strangercacaus',\n    repo='florianopolis_rent_pricing_monitoring')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:59.189511Z","iopub.status.idle":"2023-10-27T19:47:59.190052Z","shell.execute_reply.started":"2023-10-27T19:47:59.189835Z","shell.execute_reply":"2023-10-27T19:47:59.189858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#file_path = 'dataset.csv'\n#new_content = api.result_set\n#method = 'overwrite'\n#git.update_file_content(file_path, new_content, method='overwrite')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:59.191452Z","iopub.status.idle":"2023-10-27T19:47:59.191978Z","shell.execute_reply.started":"2023-10-27T19:47:59.191739Z","shell.execute_reply":"2023-10-27T19:47:59.191767Z"},"trusted":true},"execution_count":null,"outputs":[]}]}