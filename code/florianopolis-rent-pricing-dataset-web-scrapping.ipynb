{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"markdown","source":"### Definindo Caminhos de Arquivos","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.insert(1, '/kaggle/input/florianpolis-rent-pricing-dataset/code/')\nsys.path.insert(1, '/kaggle/input/florianpolis-rent-pricing-dataset/maps/')\nsys.path.insert(1, '/kaggle/input/florianpolis-rent-pricing-dataset/data/')\nsys.path.insert(1, '/kaggle/input/florianpolis-rent-pricing-dataset/')\nfor i in sys.path:\n    print(i)","metadata":{"execution":{"iopub.status.busy":"2023-10-28T05:56:58.380947Z","iopub.execute_input":"2023-10-28T05:56:58.381303Z","iopub.status.idle":"2023-10-28T05:56:58.387578Z","shell.execute_reply.started":"2023-10-28T05:56:58.381276Z","shell.execute_reply":"2023-10-28T05:56:58.386574Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"/kaggle/working\n/kaggle/input/florianpolis-rent-pricing-dataset/\n/kaggle/input/florianpolis-rent-pricing-dataset/data/\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/\n/kaggle/input/florianpolis-rent-pricing-dataset/code/\n/kaggle/input/florianpolis-rent-pricing-dataset/\n/kaggle/input/florianpolis-rent-pricing-dataset/data\n/kaggle/input/florianpolis-rent-pricing-dataset/maps\n/kaggle/input/florianpolis-rent-pricing-dataset/code/\n/kaggle/input/florianpolis-rent-pricing-dataset/\n/kaggle/input/florianpolis-rent-pricing-dataset/code/\n/kaggle/input/florianpolis-rent-pricing-dataset/\n/kaggle/input/florianpolis-rent-pricing-dataset/code/\n/kaggle/input/florianpolis-rent-pricing-dataset/code/\n/kaggle/input/florianpolis-rent-pricing-dataset/code/apis.py\n/kaggle/input/florianpolis-rent-pricing-dataset/data/dataset.csv\n/kaggle/input/florianpolis-rent-pricing-dataset/data/.DS_Store\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_bairros/gvw_bairros.dbf\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_bairros/gvw_bairros.prj\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_bairros/gvw_bairros.shx\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_bairros/gvw_bairros.shp\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_bairros/gvw_bairros.cst\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_bairros/wfsrequest.txt\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_distritos_administrativos/gvw_distritos_administrativos.shx\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_distritos_administrativos/gvw_distritos_administrativos.prj\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_distritos_administrativos/gvw_distritos_administrativos.shp\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_distritos_administrativos/gvw_distritos_administrativos.cst\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_distritos_administrativos/wfsrequest.txt\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/gvw_distritos_administrativos/gvw_distritos_administrativos.dbf\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/regioes_administrativas/regioes_administrativas.prj\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/regioes_administrativas/regioes_administrativas.shp\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/regioes_administrativas/regioes_administrativas.shx\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/regioes_administrativas/regioes_administrativas.cst\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/regioes_administrativas/regioes_administrativas.dbf\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/regioes_administrativas/wfsrequest.txt\n/kaggle/input/florianpolis-rent-pricing-dataset/maps/.DS_Store\n/kaggle/input/florianpolis-rent-pricing-dataset/code/florianopolis-rent-pricing-dataset-eda.ipynb\n/kaggle/input/florianpolis-rent-pricing-dataset/code/.DS_Store\n/kaggle/input/florianpolis-rent-pricing-dataset/code/apis.py\n/kaggle/input/florianpolis-rent-pricing-dataset/code/florianopolis-rent-pricing-dataset-web-scrapping.ipynb\n/kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt\n/kaggle/input/florianpolis-rent-pricing-dataset/changelog.md\n/kaggle/input/florianpolis-rent-pricing-dataset/.DS_Store\n/kaggle/input/florianpolis-rent-pricing-dataset/README.md\n/kaggle/input/florianpolis-rent-pricing-dataset/.gitignore\n/kaggle/input/florianpolis-rent-pricing-dataset/LICENSE\n/kaggle/lib/kagglegym\n/kaggle/lib\n/opt/conda/lib/python310.zip\n/opt/conda/lib/python3.10\n/opt/conda/lib/python3.10/lib-dynload\n\n/root/.local/lib/python3.10/site-packages\n/opt/conda/lib/python3.10/site-packages\n/root/src/BigQuery_Helper\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Instalando pacotes via requirements.txt","metadata":{}},{"cell_type":"code","source":"!pip install -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt","metadata":{"execution":{"iopub.status.busy":"2023-10-28T05:57:16.961627Z","iopub.execute_input":"2023-10-28T05:57:16.961950Z","iopub.status.idle":"2023-10-28T05:57:26.840910Z","shell.execute_reply.started":"2023-10-28T05:57:16.961910Z","shell.execute_reply":"2023-10-28T05:57:26.840131Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Requirement already satisfied: beautifulsoup4==4.12.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 1)) (4.12.2)\nRequirement already satisfied: bs4==0.0.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 2)) (0.0.1)\nRequirement already satisfied: certifi==2023.7.22 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 3)) (2023.7.22)\nRequirement already satisfied: charset-normalizer==3.3.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 4)) (3.3.1)\nRequirement already satisfied: html5lib==1.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 5)) (1.1)\nRequirement already satisfied: idna==3.4 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 6)) (3.4)\nCollecting numpy==1.26.1 (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 7))\n  Using cached numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\nRequirement already satisfied: pandas==2.1.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 8)) (2.1.2)\nRequirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 9)) (2.8.2)\nRequirement already satisfied: pytz==2023.3.post1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 10)) (2023.3.post1)\nRequirement already satisfied: requests==2.31.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 11)) (2.31.0)\nRequirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 12)) (1.16.0)\nCollecting soupsieve==2.5 (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 13))\n  Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\nRequirement already satisfied: tzdata==2023.3 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 14)) (2023.3)\nCollecting urllib3==2.0.7 (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 15))\n  Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\nRequirement already satisfied: webencodings==0.5.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/florianpolis-rent-pricing-dataset/requrements.txt (line 16)) (0.5.1)\n\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numpy-1.25.2.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: urllib3, soupsieve, numpy\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.16\n    Uninstalling urllib3-1.26.16:\n      Successfully uninstalled urllib3-1.26.16\n  Attempting uninstall: soupsieve\n    Found existing installation: soupsieve 2.4.1\n    Uninstalling soupsieve-2.4.1:\n      Successfully uninstalled soupsieve-2.4.1\n  Attempting uninstall: numpy\n\u001b[33m    WARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n\u001b[0m    Found existing installation: numpy 1.25.2\n\u001b[31mERROR: Cannot uninstall numpy 1.25.2, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps numpy==1.25.2'.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Importando módulos","metadata":{}},{"cell_type":"code","source":"# Builtins\nfrom datetime import datetime, date\nimport requests\nimport string\nimport time\nimport re\nimport base64\nfrom random import randint\n\n# Bibliotecas Externas\nimport numpy as np\nimport pandas as pd\nimport bs4\nimport html5lib\nfrom kaggle_secrets import UserSecretsClient\n\n# Módulos Personalizados\nfrom apis import VivaRealApi","metadata":{"source_hash":null,"execution_start":1698097356201,"execution_millis":10,"deepnote_to_be_reexecuted":false,"cell_id":"e67ef1ad31fb4b8cb2868c3d9cf1f8e2","deepnote_cell_type":"code","execution":{"iopub.status.busy":"2023-10-28T05:49:25.237790Z","iopub.execute_input":"2023-10-28T05:49:25.238666Z","iopub.status.idle":"2023-10-28T05:49:25.248694Z","shell.execute_reply.started":"2023-10-28T05:49:25.238641Z","shell.execute_reply":"2023-10-28T05:49:25.247682Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Importando chaves de acesso do Github","metadata":{}},{"cell_type":"code","source":"# Importação de Chaves para integração com o Github\nuser_secrets = UserSecretsClient()\ngithub_access_token = user_secrets.get_secret(\"github_rent_price_monitoring\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:43.643944Z","iopub.execute_input":"2023-10-27T19:47:43.644350Z","iopub.status.idle":"2023-10-27T19:47:43.995899Z","shell.execute_reply.started":"2023-10-27T19:47:43.644317Z","shell.execute_reply":"2023-10-27T19:47:43.994617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classe GithubAPI: Gerencia a integração do notebook com o Github\n\nclass GithubApi():\n    def __init__(self, token:str, owner:str, repo:str) -> None:\n        \"\"\"\n        Inicia a classe GithubApi com o token de autenticação, usuário e repositório.\n        \n        Args:\n        - token: string do token pessoal ou fine-grained.\n        - owner: nome de usuário\n        - repo: nome do repositório a ser conectado\n        \n        Retorna:\n        Uma instância do objeto GithubApi\n        \"\"\"\n        self.token = token\n        self.owner = owner\n        self.repo = repo\n        self.base_url = f'https://api.github.com/repos/{owner}/{repo}'\n        \n    def get_url(self, file_path:str) -> str:\n        \"\"\"\n        Retorna uma url formatada com os parâmetros da api do usuário\n        \n        Args:\n        - file_path: O caminho para o arquivo dentro do repositório\n        \n        Retorna:\n        URL no formato\n        ```python\n        api.get_url('file.csv')\n        # https://api.github/.com/repos/cacau/florianopolis_rent_pricing_monitoring/file.csv\n        ```\n        \"\"\"\n        return f'{self.base_url}/contents/{file_path}'\n        \n    def get_file_info(self, file_url) -> str:\n        \"\"\"\n        Recupera as informações de armazenamento de um arquivo de um repositório do Github\n        \n        Args:\n        = file_url: url do arquivo obtida com a função get_url.\n        \n        Retorna:\n        download_url: Url direta do conteúdo do arquivo.\n        current_sha: chave criptografada com permissão de alterar o arquivo\n        file_url: URL de local do arquivo fornecida pelo github\n        \"\"\"\n        headers = {'Authorization': f'token {self.token}'}\n        response = requests.get(url=file_url, headers=headers)\n        response.raise_for_status()\n        response_json = response.json()\n        download_url = response_json['download_url']\n        current_sha = response_json['sha']\n        return download_url, current_sha\n    \n    def _download_current_content(self, download_url) -> pd.DataFrame:\n        \"\"\"\n        Baixa o conteúdo do arquivo a partir da url de download.\n        \n        O Método self._download_current_content analisa a string da url de download para identificar\n        o formato de arquivo e então utiliza um método de extração adequado para o tipo de formato.\n        \n        No momenro apenas o download de arquivos csv está implementado com a função pd.read_csv.\n        \n        Args:\n        - download_url: url do arquivo obtida com a função get_file_info.\n        \n        Retorna:\n        Dataframe Pandas com os valores do arquivo.\n        \"\"\"\n        extension = download_url.split('.')[-1]\n        if extension == 'csv':\n            return pd.read_csv(download_url,index_col=0)\n        elif extension == 'parquet':\n            return pd.read_csv\n        else:\n            raise TypeError(f'file format {extension} is not supported')\n                \n    def _append_new_content(self,current_content=pd.DataFrame, new_content=pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Adiciona o conteúdo do novo result_set ao Dataframe existente.\n        \n        Kwargs:\n        - current_content: Dataframe do dataset atual. \n        - new_content: Dataframe do novo result_set.\n        \n        Retorna:\n        Dataframe Pandas com os valores unidos.\n        \"\"\"\n        return pd.concat([current_content,new_content])\n    \n    def _get_encoded_content(self, appended_content=pd.DataFrame, file_format='csv'):\n        \"\"\"\n        Formata o conteúdo do dataframe para inclusão no Github\n        \n        Kwargs:\n        - appended_content: Dataframe com os valores a serem codificados para envio.\n        - file_format: O formato para codificação, CSV por padrão.\n        \n        Retorna:\n        Arquivo base64 na codificação desejada.\n        \"\"\"\n        if file_format == 'csv':\n            csv_data = appended_content.to_csv()\n            return base64.b64encode(csv_data.encode()).decode('utf-8')\n        else:\n            raise TypeError(f'Unsuported file type in _get_encoded_content function')\n    \n    def _put_content(self, headers, data, url) -> requests.models.Response:\n        \"\"\"\n        Realiza requisição PUT com payload formatado.\n        \n        Kwargs:\n        - appended_content: Dataframe com os valores a serem configurados para envio.\n        \n        Retorna:\n        Arquivo base64 na codificação desejada.\n        \"\"\"\n        try:\n            response = requests.put(url=file_url, headers=headers, json=data)\n            response.raise_for_status()\n            return response\n        except requests.HTTPError as http_err:\n            print(f'HTTP error occurred: {http_err}')\n        except Exception as err:\n            print(f'Other error occurred: {err}')\n        else:\n            if response.status_code == 200:\n                print(\"File updated successfully.\")\n            else:\n                print(f\"Failed to update file. Status code: {response.status_code}\")\n    \n    def update_file_content(self, file_path, new_content, method='append') -> None:\n        \"\"\"\n        Realiza o update do conteúdo de um arquivo a partir de um path e um novo conteúdo.\n        \n        Args:\n        - file_path: o caminho do arquivo dentro do repositório.\n        - new_content: o Dataframe com o conteúdo a ser inserido.\n        \n        Kwargs:\n        - method: 'append' Adiciona o novo conteúdo ao existente | 'overwrite' sobrescreve o conteúdo com o novo.\n        \"\"\"\n        file_url = self.get_url(file_path=file_path)\n        download_url, current_sha = self.get_file_info(file_url)\n        current_content = self._download_current_content(download_url)\n        if method == 'append':\n            appended_content = self._append_new_content(current_content, new_content)\n        elif method == 'overwrite':\n            appended_content = new_content\n        else:\n            raise TypeError('\"method\" must be one of \"append\" or \"overwrite\".')\n        encoded_content = self._get_encoded_content(appended_content)\n        commit_message = f\"Automatically updated via Kaggle script\"\n        headers = {'Authorization': f'token {self.token}'}\n        data = {\"message\": commit_message,\"content\": encoded_content,\"sha\": current_sha}\n        self._put_content(headers=headers, data=data, url=file_url)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:43.999024Z","iopub.execute_input":"2023-10-27T19:47:43.999632Z","iopub.status.idle":"2023-10-27T19:47:44.039732Z","shell.execute_reply.started":"2023-10-27T19:47:43.999586Z","shell.execute_reply":"2023-10-27T19:47:44.037901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VivaRealApi():\n    def __init__(self, cidade:str, delay_seconds=0) -> None:\n        self.type = 'Viva Real'\n        self.current_page = 1\n        self.city = cidade\n        self.delay_seconds = delay_seconds\n        self._last_http_response = None\n        self.result_set = pd.DataFrame(\n            {'data': pd.Series(dtype='datetime64[ns]'),\n             'fonte': pd.Series(dtype='str'),\n             'descricao': pd.Series(dtype='str'),\n             'endereco': pd.Series(dtype='str'),\n             'rua': pd.Series(dtype='str'),\n             'numero': pd.Series(dtype='int'),\n             'bairro': pd.Series(dtype='str'),\n             'cidade': pd.Series(dtype='str'),\n             'valor': pd.Series(dtype='float'),\n             'periodicidade': pd.Series(dtype='str'),\n             'condominio': pd.Series(dtype='float'),\n             'area': pd.Series(dtype='float'),\n             'qtd_banheiros': pd.Series(dtype='int'),\n             'qtd_quartos': pd.Series(dtype='int'),\n             'qtd_vagas': pd.Series(dtype='int'),\n             'url': pd.Series(dtype='str')\n                  })\n        \n    @property\n    def endpoint(self) -> str:\n        return f'https://www.vivareal.com.br/aluguel/santa-catarina/{self.city}/?pagina='\n    \n    @property\n    def _first_page(self) -> bs4.BeautifulSoup:\n        response = self._extract_current_page()\n        return self._parse_html_response(response=response)\n    \n    @property\n    def _result_count(self) -> int:\n        soup = self._first_page\n        try:\n            return int(soup.find('strong',{'class':'results-summary__count'}).text.replace('.',''))\n        except:\n            print(f'No houses were found for the given page.\\n the HTML structure of the page might have been altered...')\n            return 0\n        \n    @property\n    def _results_per_page(self) -> int:\n        soup = self._first_page\n        listings = self._extract_listings_from_soup(soup=soup)\n        return len(listings)\n    \n    def _get_endpoint(self) -> str:\n        seed = randint(1,6)\n        \n        match seed:\n            case 1:\n                return f'{self.endpoint}{self.current_page}#onde=Brasil,Santa%20Catarina,Florian%C3%B3polis,,,,,,BR%3ESanta%20Catarina%3ENULL%3EFlorianopolis,,,'\n            case 2:\n                return f'{self.endpoint}{self.current_page}'\n            case 3:\n                return f'{self.endpoint}{self.current_page}#onde=Florian%C3%B3polis,,,'\n            case 4:\n                return f'{self.endpoint}{self.current_page}#onde=Brasil,Santa%20Catarina,Florian%C3%B3polis,,BR%3ESanta%20Catarina%3ENULL%3EFlorianopolis,,,'\n            case 5:\n                return f'{self.endpoint}{self.current_page}#onde=Brasil,Santa%20Catarina,Florian%C3%B3polis,,,,BR%3ESanta%20Catarina%3ENULL%3EFlorianopolis,,,'\n            case 6:\n                return f'{self.endpoint}{self.current_page}#onde=,Santa%20Catarina,Florian%C3%B3polis,,,,,,,city,BR%3ESanta%20Catarina%3ENULL%3EFlorianopolis,,,'\n    \n    def _get_new_page_number(self) -> int:\n        return randint(1,round(self._result_count/self._results_per_page))\n    \n    def _extract_current_page(self, max_retries=5, backoff_factor=2) -> requests.models.Response:\n        retries = 0\n        while retries < max_retries:\n            if self.current_page > 1:\n                time.sleep(self.delay_seconds) \n            response = requests.get(self._get_endpoint())\n            if response.status_code < 300:  # Successful response\n                return response\n            elif response.status_code == 429:  # Too many requests\n                print(f\"Rate limited. Retrying in {backoff_factor ** retries} seconds.\")\n                time.sleep(backoff_factor ** retries)\n                retries += 1\n            else:\n                print(f\"Request failed with status code {response.status_code}\")\n                return None\n            self._last_http_response = response.status_code\n    \n    def _parse_html_response(self, response=None) -> bs4.BeautifulSoup:\n        if response and response.status_code < 300:\n            return bs4.BeautifulSoup(response.text, features=\"html5lib\")\n        elif response:\n            print(f'No valid response to be parsed. Status code {response.status_code}.')\n            return None\n        else:\n            print('Empty request')\n        \n    def _extract_listings_from_soup(self, soup) -> bs4.element.ResultSet:\n        return soup.find_all('article', {'class': 'property-card__container js-property-card'})\n    \n    def _format_listing(self, listing=None) -> list:\n            data = datetime.now()\n            fonte = self.type\n            cidade = self.city\n            formatted = []\n            try:\n                descricao = listing.find('span', {'class': 'js-card-title'}).text.strip()\n            except:\n                descricao = None\n            try:\n                endereco = listing.find('span', {'class': 'property-card__address'}).text.replace('-',',').replace('|','').strip()\n            except:\n                endereco = ''\n            try:\n                rua = extract_address(endereco)['rua']\n            except:\n                rua = None\n            try:\n                numero = extract_address(endereco)['numero']\n            except:\n                numero = None   \n            try:\n                bairro = extract_address(endereco)['bairro']\n            except:\n                bairro = None\n            try:\n                valor = listing.find('div', {'class': 'property-card__price'}).text.replace('R$','').replace('.','').split('/')[0]\n            except:\n                valor = None\n            try:\n                periodicidade = listing.find('div', {'class': 'property-card__price'}).text.replace('R$','').replace('.','').split('/')[1].split(' ')[0]\n            except:\n                periodicidade = None\n            try:\n                condominio = listing.find('strong', {'class': 'js-condo-price'}).text.replace('R$','').strip()\n            except:\n                condominio = None\n            try:\n                area = listing.find('span', {'class': 'js-property-card-detail-area'}).text.strip()\n            except:\n                area = None\n            try:\n                qtd_banheiros = listing.find('li', {'class': 'property-card__detail-bathroom'}).text.strip()[0]\n                qtd_banheiros = int(''.join(re.findall(r'\\d', qtd_banheiros)))\n            except:\n                qtd_banheiros = None\n            try:\n                qtd_quartos = listing.find('li', {'class': 'property-card__detail-room'}).text.strip()[0]\n                qtd_quartos = int(''.join(re.findall(r'\\d', qtd_quartos)))\n            except:\n                qtd_quartos = None\n            try:\n                qtd_vagas = listing.find('li', {'class': 'property-card__detail-garage'}).text.strip()[0]\n                qtd_vagas = int(''.join(re.findall(r'\\d', qtd_vagas)))\n            except:\n                qtd_vagas = None\n            try:\n                link = 'https://vivareal.com.br' + listing.find('a', {'class': 'property-card__labels-container'})['href']\n            except:\n                link = None\n            return [data,fonte,descricao,endereco,rua,numero,bairro,cidade,valor,periodicidade,condominio,area,qtd_banheiros,qtd_quartos,qtd_vagas,link]\n    \n    def _append_formatted_listing(self, listing=None) -> None:\n        try:\n            if not listing[-1] in self.result_set['url'].to_list():\n                self.result_set.loc[self.result_set.shape[0]] = listing\n                return True\n        except:\n            print(f'Error appending the following listing:\\n{listing}')\n            return False\n        else:\n            return False\n    \n    def _ingest_current_page(self) -> None:\n        try:\n            print(f'Current_page: {self.current_page}')\n            response = self._extract_current_page()\n            soup = self._parse_html_response(response=response)\n            listings = self._extract_listings_from_soup(soup=soup)\n            added_listings = 0\n            for i in listings:\n                formatted = self._format_listing(listing = i)\n                success = self._append_formatted_listing(listing=formatted)\n                if success == True:\n                    added_listings += 1\n        except exception:\n            print(f'Something went wrong while formating the listings of the page {self.current_page}: {exception}')\n        else:\n            print(f'{added_listings} novos anúncios adicionados na página {self.current_page}')\n            self.current_page = self._get_new_page_number()\n    \n    def ingest_listings(self, all=True, max_attempts=None) -> None:\n        attempts = 0\n        if all == True:\n            while self.result_set.shape[0] < self._result_count:\n                    self._ingest_current_page()\n                    attempts += 1\n        elif max_attempts:\n            if type(max_attempts) == int and max_attempts > 0:\n                self.current_page = 1\n                while attempts <= max_attempts:\n                    self._ingest_current_page()\n                    attempts += 1\n            else:\n                raise TypeError('pages_number: This parameter only accepts numbers above zero.')\n                \n    def dump_result_set(self, path=None, format='csv') -> None:\n        if format=='csv':\n            self.result_set.to_csv(f'{path}{self.city}_{date.today()}.csv')\n        elif format=='parquet':\n            self.result_set.to_parquet(f'{path}{self.city}_{date.today()}.parquet')\n        else:\n            print(f'Option not allowed: {format}')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:44.062860Z","iopub.execute_input":"2023-10-27T19:47:44.064460Z","iopub.status.idle":"2023-10-27T19:47:44.118757Z","shell.execute_reply.started":"2023-10-27T19:47:44.064402Z","shell.execute_reply":"2023-10-27T19:47:44.117199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fluxo de Controle","metadata":{}},{"cell_type":"code","source":"api = VivaRealApi('florianopolis',delay_seconds=2)\napi.ingest_listings(all=False, max_attempts=2)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-28T05:49:44.493250Z","iopub.execute_input":"2023-10-28T05:49:44.493552Z","iopub.status.idle":"2023-10-28T05:49:50.771367Z","shell.execute_reply.started":"2023-10-28T05:49:44.493530Z","shell.execute_reply":"2023-10-28T05:49:50.770206Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Current_page: 1\n36 novos anúncios adicionados na página 1\nCurrent_page: 133\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/kaggle/input/florianpolis-rent-pricing-dataset/code/apis.py:390\u001b[0m, in \u001b[0;36mVivaRealApi._ingest_current_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent_page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 390\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_current_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_html_response(response\u001b[38;5;241m=\u001b[39mresponse)\n","File \u001b[0;32m/kaggle/input/florianpolis-rent-pricing-dataset/code/apis.py:195\u001b[0m, in \u001b[0;36mVivaRealApi._extract_current_page\u001b[0;34m(self, max_retries, backoff_factor)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelay_seconds\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    196\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_endpoint())\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m api \u001b[38;5;241m=\u001b[39m VivaRealApi(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflorianopolis\u001b[39m\u001b[38;5;124m'\u001b[39m,delay_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mingest_listings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/kaggle/input/florianpolis-rent-pricing-dataset/code/apis.py:425\u001b[0m, in \u001b[0;36mVivaRealApi.ingest_listings\u001b[0;34m(self, all, max_attempts)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m attempts \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_attempts:\n\u001b[0;32m--> 425\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ingest_current_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m         attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/kaggle/input/florianpolis-rent-pricing-dataset/code/apis.py:399\u001b[0m, in \u001b[0;36mVivaRealApi._ingest_current_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m             added_listings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mexception\u001b[49m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSomething went wrong while formating the listings of the page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mNameError\u001b[0m: name 'exception' is not defined"],"ename":"NameError","evalue":"name 'exception' is not defined","output_type":"error"}]},{"cell_type":"code","source":"df = api.result_set\ndf['area'] = df['area'].astype('float')\ndf['valor'] = df[['valor']].astype('float')\ndf.plot(kind='scatter',x='area',y='valor')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:59.187601Z","iopub.status.idle":"2023-10-27T19:47:59.188029Z","shell.execute_reply.started":"2023-10-27T19:47:59.187829Z","shell.execute_reply":"2023-10-27T19:47:59.187849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"git = GithubApi(\n    token=github_access_token,\n    owner='strangercacaus',\n    repo='florianopolis_rent_pricing_monitoring')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:59.189511Z","iopub.status.idle":"2023-10-27T19:47:59.190052Z","shell.execute_reply.started":"2023-10-27T19:47:59.189835Z","shell.execute_reply":"2023-10-27T19:47:59.189858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#file_path = 'dataset.csv'\n#new_content = api.result_set\n#method = 'overwrite'\n#git.update_file_content(file_path, new_content, method='overwrite')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:47:59.191452Z","iopub.status.idle":"2023-10-27T19:47:59.191978Z","shell.execute_reply.started":"2023-10-27T19:47:59.191739Z","shell.execute_reply":"2023-10-27T19:47:59.191767Z"},"trusted":true},"execution_count":null,"outputs":[]}]}